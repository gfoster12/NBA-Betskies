# ML Pipeline

## Feature sets
- **Team rolling metrics** (default 5-game window) generated by `feature_engineering.build_team_rolling_features`:
  - Offensive/defensive rating proxies, pace, rebound %, turnover %, home/away rate.
- **Player rolling metrics** stubs can be added in `feature_engineering.py` using the same pattern once enriched box-score stats are ingested.
- Contextual information (spread/total odds, travel, rest) can be merged at ingestion time for future iterations.

## Training process
1. **Data prep** – `models.training._prepare_dataset()` loads engineered features, sorts by date to avoid leakage, and splits into train/validation segments.
2. **Scaling** – `StandardScaler` normalizes numeric columns; the fitted scaler is persisted next to the model artifact.
3. **Architecture** – `nn_architectures.TabularMLP` (3 hidden layers with BatchNorm, Dropout, ReLU) produces win-probability estimates via sigmoid outputs.
4. **Optimization** – Adam optimizer, BCE loss, configurable epochs/learning rate; uses GPU if available.
5. **Metrics & logging** – Accuracy, log loss, Brier score captured and stored in the `ModelRun` table together with artifact paths and timestamps. Calibration helpers live in `models/evaluation.py`.
6. **Artifacts** – Saved under `artifacts/game_outcome_<timestamp>.pt` plus matching scaler file. Metadata enables version pinning for production inference.

## Continuous learning
- `scheduling/jobs.run_daily_job` ingests the latest games/odds and (optionally) triggers fine-tuning/retraining.
- Model versions recorded in the database allow simple rollback or comparison.
- Extend daily workflow to:
  - Append freshly labeled outcomes into the training set.
  - Recompute features incrementally.
  - Trigger `python -m parlaylab.models.training --task ...` via cron or orchestration (Airflow, Prefect, Dagster, etc.).

## Evaluation extras
- `evaluation.calibration_table` + `plot_calibration` enable dashboard/ML monitoring integration.
- Add new tasks (totals, player props) by creating dedicated datasets + modeling functions, reusing artifact/version logging patterns.
